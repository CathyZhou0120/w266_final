{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import ast\n",
    "import glove_helper\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "import keras\n",
    "from itertools import groupby\n",
    "from os.path import basename, splitext\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import regex as re\n",
    "import ast\n",
    "import glove_helper\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from itertools import groupby\n",
    "from os.path import basename, splitext\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathyzhou/anaconda3/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(project='manifest-frame-203601')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = (\n",
    "    \"\"\"\n",
    "    select distinct repo_path,c_content from w266_final.final_20k\n",
    "    \"\"\")\n",
    "query_job = client.query(QUERY)  # API request\n",
    "rows = query_job.result()  # Waits for query to finish\n",
    "\n",
    "df = []\n",
    "for row in rows:\n",
    "    df.append([row.repo_path,row.c_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172413, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.columns = ['repo_path','content']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(docstring_list):\n",
    "    \n",
    "    \"\"\"takes a list of doc strings and converts to a single flat list of tokens\"\"\"\n",
    "    \n",
    "    tokens = [tf.keras.preprocessing.text.text_to_word_sequence(i) for i in docstring_list]\n",
    "    flat_tokens = [item for sublist in tokens for item in sublist]\n",
    "    flat_string = \" \".join(flat_tokens)\n",
    "    \n",
    "    return flat_string\n",
    "\n",
    "def get_docstrings(source):\n",
    "    \n",
    "    \"\"\"function to walk through parse tree and return list of docstrings\"\"\"\n",
    "    \n",
    "    NODE_TYPES = {\n",
    "    ast.ClassDef: 'Class',\n",
    "    ast.FunctionDef: 'Function/Method',\n",
    "    ast.Module: 'Module'\n",
    "    }\n",
    "    \n",
    "    docstrings = []\n",
    "    \n",
    "    try:\n",
    "        tree = ast.parse(source)\n",
    "    except:\n",
    "        return \" \"\n",
    "       \n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, tuple(NODE_TYPES)):\n",
    "            docstring = ast.get_docstring(node)\n",
    "            docstrings.append(docstring)\n",
    "    \n",
    "    docstrings =  [x for x in docstrings if x is not None]\n",
    "    clean_string = cleanup(docstrings)\n",
    "            \n",
    "    return clean_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_path</th>\n",
       "      <th>content</th>\n",
       "      <th>docstrings</th>\n",
       "      <th>docstring2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ilogue/niprov tests/test_mediumviewer.py</td>\n",
       "      <td>#!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\nfr...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UndeadMastodon/Loltris Matrix.py</td>\n",
       "      <td>#!/usr/bin/python2\\n#-*- coding: utf-8 -*-\\n\\n...</td>\n",
       "      <td>prints a matrix to the console for debugging p...</td>\n",
       "      <td>[[prints, a, matrix, to, the, console, for, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anhstudios/swganh data/scripts/templates/objec...</td>\n",
       "      <td>#### NOTICE: THIS FILE IS AUTOGENERATED\\n#### ...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Southpaw-TACTIC/TACTIC src/bin/example/add_fla...</td>\n",
       "      <td>import sys\\r\\nimport tacticenv\\r\\n\\r\\n\\r\\nfrom...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scrapinghub/exporters exporters/writers/dropbo...</td>\n",
       "      <td>from collections import Counter\\nfrom exporter...</td>\n",
       "      <td>writes items to dropbox folder options availab...</td>\n",
       "      <td>[[writes, items, to, dropbox, folder, options,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           repo_path  \\\n",
       "0           ilogue/niprov tests/test_mediumviewer.py   \n",
       "1                   UndeadMastodon/Loltris Matrix.py   \n",
       "2  anhstudios/swganh data/scripts/templates/objec...   \n",
       "3  Southpaw-TACTIC/TACTIC src/bin/example/add_fla...   \n",
       "4  scrapinghub/exporters exporters/writers/dropbo...   \n",
       "\n",
       "                                             content  \\\n",
       "0  #!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\nfr...   \n",
       "1  #!/usr/bin/python2\\n#-*- coding: utf-8 -*-\\n\\n...   \n",
       "2  #### NOTICE: THIS FILE IS AUTOGENERATED\\n#### ...   \n",
       "3  import sys\\r\\nimport tacticenv\\r\\n\\r\\n\\r\\nfrom...   \n",
       "4  from collections import Counter\\nfrom exporter...   \n",
       "\n",
       "                                          docstrings  \\\n",
       "0                                                      \n",
       "1  prints a matrix to the console for debugging p...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  writes items to dropbox folder options availab...   \n",
       "\n",
       "                                          docstring2  \n",
       "0                                               [[]]  \n",
       "1  [[prints, a, matrix, to, the, console, for, de...  \n",
       "2                                               [[]]  \n",
       "3                                               [[]]  \n",
       "4  [[writes, items, to, dropbox, folder, options,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['docstrings'] = [get_docstrings(x) for x in list(df['content'])]\n",
    "doc = []\n",
    "for i in df['docstrings']:\n",
    "    doc.append([i.split()])\n",
    "df['docstring2'] = doc\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(model):\n",
    "    # convert the wv word vectors into a numpy matrix that is suitable for insertion\n",
    "    # into our TensorFlow and Keras models\n",
    "    embedding_matrix = np.zeros((len(model.wv.vocab), 100))\n",
    "    for i in range(len(model.wv.vocab)):\n",
    "        embedding_vector = model.wv[model.wv.index2word[i]]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = []\n",
    "vector_dim = 100\n",
    "for i in df['docstring2']:\n",
    "    #print(i[0])\n",
    " #   print(i)\n",
    "    if len(i[0]) ==0:\n",
    "        embed.append([[[0]]])\n",
    "    else:\n",
    "        model = Word2Vec(i, sg=1,iter=10, min_count=1, size=100, workers=4)\n",
    "        embedding_matrix = create_embedding_matrix(model)\n",
    "        embed.append([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc_string_embed']=embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_path</th>\n",
       "      <th>content</th>\n",
       "      <th>docstrings</th>\n",
       "      <th>docstring2</th>\n",
       "      <th>doc_string_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ilogue/niprov tests/test_mediumviewer.py</td>\n",
       "      <td>#!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\nfr...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UndeadMastodon/Loltris Matrix.py</td>\n",
       "      <td>#!/usr/bin/python2\\n#-*- coding: utf-8 -*-\\n\\n...</td>\n",
       "      <td>prints a matrix to the console for debugging p...</td>\n",
       "      <td>[[prints, a, matrix, to, the, console, for, de...</td>\n",
       "      <td>[[[-0.0015476032858714461, 0.00098642380908131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anhstudios/swganh data/scripts/templates/objec...</td>\n",
       "      <td>#### NOTICE: THIS FILE IS AUTOGENERATED\\n#### ...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Southpaw-TACTIC/TACTIC src/bin/example/add_fla...</td>\n",
       "      <td>import sys\\r\\nimport tacticenv\\r\\n\\r\\n\\r\\nfrom...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scrapinghub/exporters exporters/writers/dropbo...</td>\n",
       "      <td>from collections import Counter\\nfrom exporter...</td>\n",
       "      <td>writes items to dropbox folder options availab...</td>\n",
       "      <td>[[writes, items, to, dropbox, folder, options,...</td>\n",
       "      <td>[[[-0.0005623144679702818, 0.00231970450840890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>astrofrog/sedfitter sedfitter/convolve/monochr...</td>\n",
       "      <td>from __future__ import print_function, divisio...</td>\n",
       "      <td>convolve all the model seds in a model directo...</td>\n",
       "      <td>[[convolve, all, the, model, seds, in, a, mode...</td>\n",
       "      <td>[[[-0.0003378069377504289, 0.00475694937631487...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>materialsproject/pymatgen pymatgen/core/tests/...</td>\n",
       "      <td># coding: utf-8\\n# Copyright (c) Pymatgen Deve...</td>\n",
       "      <td>testing xcfunc api</td>\n",
       "      <td>[[testing, xcfunc, api]]</td>\n",
       "      <td>[[[-0.00021332580945454538, -0.000282575783785...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dnerdy/namesync namesync/providers/cloudflare.py</td>\n",
       "      <td>import json\\n\\nfrom namesync.exceptions import...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kamyu104/LeetCode Python/path-sum-ii.py</td>\n",
       "      <td>from __future__ import print_function\\n# Time:...</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>beiko-lab/gengis bin/Lib/site-packages/numpy/d...</td>\n",
       "      <td>\\r\\n# http://www.pgroup.com\\r\\n\\r\\nfrom numpy....</td>\n",
       "      <td></td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0]]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           repo_path  \\\n",
       "0           ilogue/niprov tests/test_mediumviewer.py   \n",
       "1                   UndeadMastodon/Loltris Matrix.py   \n",
       "2  anhstudios/swganh data/scripts/templates/objec...   \n",
       "3  Southpaw-TACTIC/TACTIC src/bin/example/add_fla...   \n",
       "4  scrapinghub/exporters exporters/writers/dropbo...   \n",
       "5  astrofrog/sedfitter sedfitter/convolve/monochr...   \n",
       "6  materialsproject/pymatgen pymatgen/core/tests/...   \n",
       "7   dnerdy/namesync namesync/providers/cloudflare.py   \n",
       "8            kamyu104/LeetCode Python/path-sum-ii.py   \n",
       "9  beiko-lab/gengis bin/Lib/site-packages/numpy/d...   \n",
       "\n",
       "                                             content  \\\n",
       "0  #!/usr/bin/python\\n# -*- coding: UTF-8 -*-\\nfr...   \n",
       "1  #!/usr/bin/python2\\n#-*- coding: utf-8 -*-\\n\\n...   \n",
       "2  #### NOTICE: THIS FILE IS AUTOGENERATED\\n#### ...   \n",
       "3  import sys\\r\\nimport tacticenv\\r\\n\\r\\n\\r\\nfrom...   \n",
       "4  from collections import Counter\\nfrom exporter...   \n",
       "5  from __future__ import print_function, divisio...   \n",
       "6  # coding: utf-8\\n# Copyright (c) Pymatgen Deve...   \n",
       "7  import json\\n\\nfrom namesync.exceptions import...   \n",
       "8  from __future__ import print_function\\n# Time:...   \n",
       "9  \\r\\n# http://www.pgroup.com\\r\\n\\r\\nfrom numpy....   \n",
       "\n",
       "                                          docstrings  \\\n",
       "0                                                      \n",
       "1  prints a matrix to the console for debugging p...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  writes items to dropbox folder options availab...   \n",
       "5  convolve all the model seds in a model directo...   \n",
       "6                                 testing xcfunc api   \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "\n",
       "                                          docstring2  \\\n",
       "0                                               [[]]   \n",
       "1  [[prints, a, matrix, to, the, console, for, de...   \n",
       "2                                               [[]]   \n",
       "3                                               [[]]   \n",
       "4  [[writes, items, to, dropbox, folder, options,...   \n",
       "5  [[convolve, all, the, model, seds, in, a, mode...   \n",
       "6                           [[testing, xcfunc, api]]   \n",
       "7                                               [[]]   \n",
       "8                                               [[]]   \n",
       "9                                               [[]]   \n",
       "\n",
       "                                    doc_string_embed  \n",
       "0                                            [[[0]]]  \n",
       "1  [[[-0.0015476032858714461, 0.00098642380908131...  \n",
       "2                                            [[[0]]]  \n",
       "3                                            [[[0]]]  \n",
       "4  [[[-0.0005623144679702818, 0.00231970450840890...  \n",
       "5  [[[-0.0003378069377504289, 0.00475694937631487...  \n",
       "6  [[[-0.00021332580945454538, -0.000282575783785...  \n",
       "7                                            [[[0]]]  \n",
       "8                                            [[[0]]]  \n",
       "9                                            [[[0]]]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_search(words):\n",
    "    words_l = words.split()\n",
    "    model = Word2Vec(words_l, sg=1, min_count=1, size=100, workers=4)\n",
    "    embedding_matrix = create_embedding_matrix(model)\n",
    "    return (embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nn(words, embeddings):\n",
    "    \n",
    "    search = embed_search(words)\n",
    "    distances = [scipy.spatial.distance.cosine(search[0], i[0][0][0]) for i in embeddings]\n",
    "    nn = np.argsort(np.asarray(distances))\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_code(search_terms, docstrings, embeddings, n):\n",
    "    \n",
    "    top_n = find_nn(search_terms, embeddings)[0:n]\n",
    "    code = [df['content'].iloc[i] for i in top_n]\n",
    "    \n",
    "    return code\n",
    "    #return top_n\n",
    "    \n",
    "#search = \"model for LSTM network\"\n",
    "doc_strings = list(df['docstrings'])\n",
    "embed_vecs = list(df['doc_string_embed'])\n",
    "\n",
    "#print(top_n_code(search, doc_strings, embed_vecs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathyzhou/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -*- coding: utf-8 -*-\r\n",
      "\"\"\"\r\n",
      "/***************************************************************************\r\n",
      "    Useful network functions\r\n",
      "                             -------------------\r\n",
      "    begin            : 2011-03-01\r\n",
      "    copyright        : (C) 2011 by Luiz Motta\r\n",
      "    author           : Luiz P. Motta\r\n",
      "    email            : motta _dot_ luiz _at_ gmail.com\r\n",
      " ***************************************************************************/\r\n",
      "\r\n",
      "/***************************************************************************\r\n",
      " *                                                                         *\r\n",
      " *   This program is free software; you can redistribute it and/or modify  *\r\n",
      " *   it under the terms of the GNU General Public License as published by  *\r\n",
      " *   the Free Software Foundation; either version 2 of the License, or     *\r\n",
      " *   (at your option) any later version.                                   *\r\n",
      " *                                                                         *\r\n",
      " ***************************************************************************/\r\n",
      "\"\"\"\r\n",
      "from PyQt4.QtCore import *\r\n",
      "from PyQt4.QtNetwork import *\r\n",
      "\r\n",
      "def getProxy():\r\n",
      "    \r\n",
      "    # Adaption by source of \"Plugin Installer - Version 1.0.10\" \r\n",
      "    proxy = None\r\n",
      "    settings = QSettings()\r\n",
      "    settings.beginGroup(\"proxy\")\r\n",
      "    \r\n",
      "    #Check if the 'proxy' group exists\r\n",
      "    proxyKeys = settings.childKeys()\r\n",
      "    if len(proxyKeys) == 0:\r\n",
      "        return\r\n",
      "    \r\n",
      "    if settings.value(\"/proxyEnabled\",type=bool):\r\n",
      "        proxy = QNetworkProxy()\r\n",
      "        proxyType = settings.value(\"/proxyType\",\"\")\r\n",
      "        #if len(args)>0 and settings.value(\"/proxyExcludedUrls\").toString().contains(args[0]):\r\n",
      "        #  proxyType = \"NoProxy\"\r\n",
      "        if proxyType in [\"1\",\"Socks5Proxy\"]:\r\n",
      "            proxy.setType(QNetworkProxy.Socks5Proxy)\r\n",
      "        elif proxyType in [\"2\",\"NoProxy\"]:\r\n",
      "            proxy.setType(QNetworkProxy.NoProxy)\r\n",
      "        elif proxyType in [\"3\",\"HttpProxy\"]:\r\n",
      "            proxy.setType(QNetworkProxy.HttpProxy)\r\n",
      "        elif proxyType in [\"4\",\"HttpCachingProxy\"] and QT_VERSION >= 0X040400:\r\n",
      "            proxy.setType(QNetworkProxy.HttpCachingProxy)\r\n",
      "        elif proxyType in [\"5\",\"FtpCachingProxy\"] and QT_VERSION >= 0X040400:\r\n",
      "            proxy.setType(QNetworkProxy.FtpCachingProxy)\r\n",
      "        else: \r\n",
      "            proxy.setType(QNetworkProxy.DefaultProxy)\r\n",
      "            proxy.setHostName(settings.value(\"/proxyHost\"))\r\n",
      "            port = settings.value(\"/proxyPort\")\r\n",
      "            if port != \"\":\r\n",
      "                proxy.setPort(int(port))\r\n",
      "            proxy.setUser(settings.value(\"/proxyUser\"))\r\n",
      "            proxy.setPassword(settings.value(\"/proxyPassword\"))\r\n",
      "    \r\n",
      "    settings.endGroup()\r\n",
      "    return proxy\n"
     ]
    }
   ],
   "source": [
    "search1 = \"model for LSTM network\"\n",
    "query1 = (top_n_code(search1, doc_strings, embed_vecs, 5))\n",
    "print(query1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathyzhou/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:698: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -*- coding: utf-8 -*-\r\n",
      "\"\"\"\r\n",
      "/***************************************************************************\r\n",
      "    Useful network functions\r\n",
      "                             -------------------\r\n",
      "    begin            : 2011-03-01\r\n",
      "    copyright        : (C) 2011 by Luiz Motta\r\n",
      "    author           : Luiz P. Motta\r\n",
      "    email            : motta _dot_ luiz _at_ gmail.com\r\n",
      " ***************************************************************************/\r\n",
      "\r\n",
      "/***************************************************************************\r\n",
      " *                                                                         *\r\n",
      " *   This program is free software; you can redistribute it and/or modify  *\r\n",
      " *   it under the terms of the GNU General Public License as published by  *\r\n",
      " *   the Free Software Foundation; either version 2 of the License, or     *\r\n",
      " *   (at your option) any later version.                                   *\r\n",
      " *                                                                         *\r\n",
      " ***************************************************************************/\r\n",
      "\"\"\"\r\n",
      "from PyQt4.QtCore import *\r\n",
      "from PyQt4.QtNetwork import *\r\n",
      "\r\n",
      "def getProxy():\r\n",
      "    \r\n",
      "    # Adaption by source of \"Plugin Installer - Version 1.0.10\" \r\n",
      "    proxy = None\r\n",
      "    settings = QSettings()\r\n",
      "    settings.beginGroup(\"proxy\")\r\n",
      "    \r\n",
      "    #Check if the 'proxy' group exists\r\n",
      "    proxyKeys = settings.childKeys()\r\n",
      "    if len(proxyKeys) == 0:\r\n",
      "        return\r\n",
      "    \r\n",
      "    if settings.value(\"/proxyEnabled\",type=bool):\r\n",
      "        proxy = QNetworkProxy()\r\n",
      "        proxyType = settings.value(\"/proxyType\",\"\")\r\n",
      "        #if len(args)>0 and settings.value(\"/proxyExcludedUrls\").toString().contains(args[0]):\r\n",
      "        #  proxyType = \"NoProxy\"\r\n",
      "        if proxyType in [\"1\",\"Socks5Proxy\"]:\r\n",
      "            proxy.setType(QNetworkProxy.Socks5Proxy)\r\n",
      "        elif proxyType in [\"2\",\"NoProxy\"]:\r\n",
      "            proxy.setType(QNetworkProxy.NoProxy)\r\n",
      "        elif proxyType in [\"3\",\"HttpProxy\"]:\r\n",
      "            proxy.setType(QNetworkProxy.HttpProxy)\r\n",
      "        elif proxyType in [\"4\",\"HttpCachingProxy\"] and QT_VERSION >= 0X040400:\r\n",
      "            proxy.setType(QNetworkProxy.HttpCachingProxy)\r\n",
      "        elif proxyType in [\"5\",\"FtpCachingProxy\"] and QT_VERSION >= 0X040400:\r\n",
      "            proxy.setType(QNetworkProxy.FtpCachingProxy)\r\n",
      "        else: \r\n",
      "            proxy.setType(QNetworkProxy.DefaultProxy)\r\n",
      "            proxy.setHostName(settings.value(\"/proxyHost\"))\r\n",
      "            port = settings.value(\"/proxyPort\")\r\n",
      "            if port != \"\":\r\n",
      "                proxy.setPort(int(port))\r\n",
      "            proxy.setUser(settings.value(\"/proxyUser\"))\r\n",
      "            proxy.setPassword(settings.value(\"/proxyPassword\"))\r\n",
      "    \r\n",
      "    settings.endGroup()\r\n",
      "    return proxy\n"
     ]
    }
   ],
   "source": [
    "search2 = \"train a model for image recognition\"\n",
    "query2 = (top_n_code(search2, doc_strings, embed_vecs, 5))\n",
    "print(query1[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
