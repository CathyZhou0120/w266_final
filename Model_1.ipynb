{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew_mamroth/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tools import glove_helper\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from itertools import groupby\n",
    "from os.path import basename, splitext\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the script, you will need to CMD and authenticate with \n",
    "\n",
    "'gcloud auth application-default login'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew_mamroth/anaconda3/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(project='manifest-frame-203601')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = (\n",
    "    \"\"\"\n",
    "    select * from w266_final.final_20k\n",
    "    LIMIT 20000\"\"\")\n",
    "query_job = client.query(QUERY)  # API request\n",
    "rows = query_job.result()  # Waits for query to finish\n",
    "\n",
    "df = []\n",
    "for row in rows:\n",
    "    df.append([row.repo_path,row.c_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_path</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>napalm-automation/napalm-yang napalm_yang/mode...</td>\n",
       "      <td># -*- coding: utf-8 -*-\\nfrom operator import ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>napalm-automation/napalm-yang napalm_yang/mode...</td>\n",
       "      <td># -*- coding: utf-8 -*-\\nfrom operator import ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hq6/smux smux.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\n# Copyright (c) 2014-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lloda/ra-ra ra.py</td>\n",
       "      <td># -*- mode: Python -*-\\n# -*- coding: utf-8 -*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dcos/dcos setup.py</td>\n",
       "      <td>from setuptools import setup\\n\\n\\ndef get_adva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           repo_path  \\\n",
       "0  napalm-automation/napalm-yang napalm_yang/mode...   \n",
       "1  napalm-automation/napalm-yang napalm_yang/mode...   \n",
       "2                                   hq6/smux smux.py   \n",
       "3                                  lloda/ra-ra ra.py   \n",
       "4                                 dcos/dcos setup.py   \n",
       "\n",
       "                                             content  \n",
       "0  # -*- coding: utf-8 -*-\\nfrom operator import ...  \n",
       "1  # -*- coding: utf-8 -*-\\nfrom operator import ...  \n",
       "2  #!/usr/bin/env python\\n\\n# Copyright (c) 2014-...  \n",
       "3  # -*- mode: Python -*-\\n# -*- coding: utf-8 -*...  \n",
       "4  from setuptools import setup\\n\\n\\ndef get_adva...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.columns = ['repo_path','content']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(docstring_list):\n",
    "    \n",
    "    \"\"\"takes a list of doc strings and converts to a single flat list of tokens\"\"\"\n",
    "    \n",
    "    tokens = [tf.keras.preprocessing.text.text_to_word_sequence(i) for i in docstring_list]\n",
    "    flat_tokens = [item for sublist in tokens for item in sublist]\n",
    "    flat_string = \" \".join(flat_tokens)\n",
    "    \n",
    "    return flat_string\n",
    "\n",
    "def get_docstrings(source):\n",
    "    \n",
    "    \"\"\"function to walk through parse tree and return list of docstrings\"\"\"\n",
    "    \n",
    "    NODE_TYPES = {\n",
    "    ast.ClassDef: 'Class',\n",
    "    ast.FunctionDef: 'Function/Method',\n",
    "    ast.Module: 'Module'\n",
    "    }\n",
    "    \n",
    "    docstrings = []\n",
    "    \n",
    "    try:\n",
    "        tree = ast.parse(source)\n",
    "    except:\n",
    "        return \" \"\n",
    "       \n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, tuple(NODE_TYPES)):\n",
    "            docstring = ast.get_docstring(node)\n",
    "            docstrings.append(docstring)\n",
    "    \n",
    "    docstrings =  [x for x in docstrings if x is not None]\n",
    "    clean_string = cleanup(docstrings)\n",
    "            \n",
    "    return clean_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['docstrings'] = [get_docstrings(x) for x in list(df['content'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from data/glove/glove.6B.zip\n",
      "Parsing file: data/glove/glove.6B.zip:glove.6B.100d.txt\n",
      "Found 400,000 words.\n",
      "Parsing vectors... Done! (W.shape = (400003, 100))\n"
     ]
    }
   ],
   "source": [
    "hands = glove_helper.Hands(ndim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up corpus for count vectorizer\n",
    "corpus = list(df['docstrings'])\n",
    "\n",
    "#count values for tfidf calculations\n",
    "count_vect = CountVectorizer()\n",
    "count_vect = count_vect.fit(corpus)\n",
    "freq_term_matrix = count_vect.transform(corpus)\n",
    "\n",
    "#to grab columns for words\n",
    "vocab = count_vect.vocabulary_\n",
    "\n",
    "#create a holder for the new df column\n",
    "embeddings_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_embed(words):\n",
    "    \n",
    "    global count_vect, freq_term_matrix, vocab\n",
    "    \n",
    "    #verify there are docstrings available\n",
    "    if len(words)==0:\n",
    "        return np.zeros(100)\n",
    "         \n",
    "    #create tfidf for each document\n",
    "    tfidf = TfidfTransformer(norm=\"l2\")\n",
    "    tfidf.fit(freq_term_matrix)\n",
    "    doc_freq_term = count_vect.transform([words])\n",
    "    idfs = tfidf.transform(doc_freq_term)\n",
    "\n",
    "    #split the docstrings to individual words for average\n",
    "    sent_list = words.split(\" \")\n",
    "    embeddings = []\n",
    "\n",
    "    #cycle through list of words in docstring\n",
    "    for i in range(len(sent_list)):\n",
    "\n",
    "        if sent_list[i] in vocab:\n",
    "\n",
    "            col = vocab[sent_list[i]]\n",
    "            embed = hands.get_vector(sent_list[i], strict=False)\n",
    "            tfidf = idfs[0, col]\n",
    "            embeddings.append(np.multiply(embed, tfidf))\n",
    "\n",
    "        embed_array = np.asarray(embeddings)\n",
    "        \n",
    "        if len(embed_array)==0:\n",
    "            return np.zeros(100)\n",
    "\n",
    "        return np.mean(embed_array, axis=0)\n",
    "    \n",
    "def find_nn(words, embeddings):\n",
    "    \n",
    "    search = words_to_embed(words)\n",
    "    distances = [scipy.spatial.distance.cosine(search, i) for i in embeddings]\n",
    "    nn = np.argsort(np.asarray(distances))\n",
    "    \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embeddings'] = [words_to_embed(x) for x in list(df['docstrings'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_code(search_terms, docstrings, embeddings, n):\n",
    "    \n",
    "    top_n = find_nn(search_terms, embeddings)[0:n]\n",
    "    code = [df['content'][i] for i in top_n]\n",
    "    \n",
    "    return code\n",
    "\n",
    "doc_strings = list(df['docstrings'])\n",
    "embed_vecs = list(df['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew_mamroth/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "search1 = \"function that calculates distance\"\n",
    "query1 = top_n_code(search1, doc_strings, embed_vecs, 10)\n",
    "\n",
    "output11 = open('model_1_queries/mod1_q1.txt', 'w')\n",
    "for item in query1:\n",
    "    output11.write(\"************************** NEXT RESULT **************************************\\n\")\n",
    "    output11.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew_mamroth/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2017, Henrique Miranda\n",
      "# All rights reserved.\n",
      "#\n",
      "# This file is part of the phononwebsite project\n",
      "#\n",
      "\"\"\" Code the dictionary in json format \"\"\"\n",
      "import json\n",
      "import numpy as np\n",
      "\n",
      "class JsonEncoder(json.JSONEncoder):\n",
      "    def default(self, obj):\n",
      "        if isinstance(obj, (np.ndarray,np.number)):\n",
      "            if np.iscomplexobj(obj):\n",
      "                return [obj.real, obj.imag]\n",
      "            else:\n",
      "                return obj.tolist()\n",
      "        return(json.JSONEncoder.default(self, obj))\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search2 = \"code to merge two files\"\n",
    "query2 = top_n_code(search2, doc_strings, embed_vecs, 10)\n",
    "print(query2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew_mamroth/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import tensorflow as tf\n",
      "import matplotlib.pyplot as plt\n",
      "import cPickle as pickle\n",
      "import copy\n",
      "import json\n",
      "from tqdm import tqdm\n",
      "\n",
      "from utils.nn import NN\n",
      "from utils.coco.coco import COCO\n",
      "from utils.coco.pycocoevalcap.eval import COCOEvalCap\n",
      "from utils.misc import ImageLoader, CaptionData, TopN\n",
      "\n",
      "class BaseModel(object):\n",
      "    def __init__(self, config):\n",
      "        self.config = config\n",
      "        self.is_train = True if config.phase == 'train' else False\n",
      "        self.train_cnn = self.is_train and config.train_cnn\n",
      "        self.image_loader = ImageLoader('./utils/ilsvrc_2012_mean.npy')\n",
      "        self.image_shape = [224, 224, 3]\n",
      "        self.nn = NN(config)\n",
      "        self.global_step = tf.Variable(0,\n",
      "                                       name = 'global_step',\n",
      "                                       trainable = False)\n",
      "        self.build()\n",
      "\n",
      "    def build(self):\n",
      "        raise NotImplementedError()\n",
      "\n",
      "    def train(self, sess, train_data):\n",
      "        \"\"\" Train the model using the COCO train2014 data. \"\"\"\n",
      "        print(\"Training the model...\")\n",
      "        config = self.config\n",
      "\n",
      "        if not os.path.exists(config.summary_dir):\n",
      "            os.mkdir(config.summary_dir)\n",
      "        train_writer = tf.summary.FileWriter(config.summary_dir,\n",
      "                                             sess.graph)\n",
      "\n",
      "        for _ in tqdm(list(range(config.num_epochs)), desc='epoch'):\n",
      "            for _ in tqdm(list(range(train_data.num_batches)), desc='batch'):\n",
      "                batch = train_data.next_batch()\n",
      "                image_files, sentences, masks = batch\n",
      "                images = self.image_loader.load_images(image_files)\n",
      "                feed_dict = {self.images: images,\n",
      "                             self.sentences: sentences,\n",
      "                             self.masks: masks}\n",
      "                _, summary, global_step = sess.run([self.opt_op,\n",
      "                                                    self.summary,\n",
      "                                                    self.global_step],\n",
      "                                                    feed_dict=feed_dict)\n",
      "                if (global_step + 1) % config.save_period == 0:\n",
      "                    self.save()\n",
      "                train_writer.add_summary(summary, global_step)\n",
      "            train_data.reset()\n",
      "\n",
      "        self.save()\n",
      "        train_writer.close()\n",
      "        print(\"Training complete.\")\n",
      "\n",
      "    def eval(self, sess, eval_gt_coco, eval_data, vocabulary):\n",
      "        \"\"\" Evaluate the model using the COCO val2014 data. \"\"\"\n",
      "        print(\"Evaluating the model ...\")\n",
      "        config = self.config\n",
      "\n",
      "        results = []\n",
      "        if not os.path.exists(config.eval_result_dir):\n",
      "            os.mkdir(config.eval_result_dir)\n",
      "\n",
      "        # Generate the captions for the images\n",
      "        idx = 0\n",
      "        for k in tqdm(list(range(eval_data.num_batches)), desc='batch'):\n",
      "            batch = eval_data.next_batch()\n",
      "            caption_data = self.beam_search(sess, batch, vocabulary)\n",
      "\n",
      "            fake_cnt = 0 if k<eval_data.num_batches-1 \\\n",
      "                         else eval_data.fake_count\n",
      "            for l in range(eval_data.batch_size-fake_cnt):\n",
      "                word_idxs = caption_data[l][0].sentence\n",
      "                score = caption_data[l][0].score\n",
      "                caption = vocabulary.get_sentence(word_idxs)\n",
      "                results.append({'image_id': eval_data.image_ids[idx],\n",
      "                                'caption': caption})\n",
      "                idx += 1\n",
      "\n",
      "                # Save the result in an image file, if requested\n",
      "                if config.save_eval_result_as_image:\n",
      "                    image_file = batch[l]\n",
      "                    image_name = image_file.split(os.sep)[-1]\n",
      "                    image_name = os.path.splitext(image_name)[0]\n",
      "                    img = plt.imread(image_file)\n",
      "                    plt.imshow(img)\n",
      "                    plt.axis('off')\n",
      "                    plt.title(caption)\n",
      "                    plt.savefig(os.path.join(config.eval_result_dir,\n",
      "                                             image_name+'_result.jpg'))\n",
      "\n",
      "        fp = open(config.eval_result_file, 'wb')\n",
      "        json.dump(results, fp)\n",
      "        fp.close()\n",
      "\n",
      "        # Evaluate these captions\n",
      "        eval_result_coco = eval_gt_coco.loadRes(config.eval_result_file)\n",
      "        scorer = COCOEvalCap(eval_gt_coco, eval_result_coco)\n",
      "        scorer.evaluate()\n",
      "        print(\"Evaluation complete.\")\n",
      "\n",
      "    def test(self, sess, test_data, vocabulary):\n",
      "        \"\"\" Test the model using any given images. \"\"\"\n",
      "        print(\"Testing the model ...\")\n",
      "        config = self.config\n",
      "\n",
      "        if not os.path.exists(config.test_result_dir):\n",
      "            os.mkdir(config.test_result_dir)\n",
      "\n",
      "        captions = []\n",
      "        scores = []\n",
      "\n",
      "        # Generate the captions for the images\n",
      "        for k in tqdm(list(range(test_data.num_batches)), desc='path'):\n",
      "            batch = test_data.next_batch()\n",
      "            caption_data = self.beam_search(sess, batch, vocabulary)\n",
      "\n",
      "            fake_cnt = 0 if k<test_data.num_batches-1 \\\n",
      "                         else test_data.fake_count\n",
      "            for l in range(test_data.batch_size-fake_cnt):\n",
      "                word_idxs = caption_data[l][0].sentence\n",
      "                score = caption_data[l][0].score\n",
      "                caption = vocabulary.get_sentence(word_idxs)\n",
      "                captions.append(caption)\n",
      "                scores.append(score)\n",
      "\n",
      "                # Save the result in an image file\n",
      "                image_file = batch[l]\n",
      "                image_name = image_file.split(os.sep)[-1]\n",
      "                image_name = os.path.splitext(image_name)[0]\n",
      "                img = plt.imread(image_file)\n",
      "                plt.imshow(img)\n",
      "                plt.axis('off')\n",
      "                plt.title(caption)\n",
      "                plt.savefig(os.path.join(config.test_result_dir,\n",
      "                                         image_name+'_result.jpg'))\n",
      "\n",
      "        # Save the captions to a file\n",
      "        results = pd.DataFrame({'image_files':test_data.image_files,\n",
      "                                'caption':captions,\n",
      "                                'prob':scores})\n",
      "        results.to_csv(config.test_result_file)\n",
      "        print(\"Testing complete.\")\n",
      "\n",
      "    def beam_search(self, sess, image_files, vocabulary):\n",
      "        \"\"\"Use beam search to generate the captions for a batch of images.\"\"\"\n",
      "        # Feed in the images to get the contexts and the initial LSTM states\n",
      "        config = self.config\n",
      "        images = self.image_loader.load_images(image_files)\n",
      "        contexts, initial_memory, initial_output = sess.run(\n",
      "            [self.conv_feats, self.initial_memory, self.initial_output],\n",
      "            feed_dict = {self.images: images})\n",
      "\n",
      "        partial_caption_data = []\n",
      "        complete_caption_data = []\n",
      "        for k in range(config.batch_size):\n",
      "            initial_beam = CaptionData(sentence = [],\n",
      "                                       memory = initial_memory[k],\n",
      "                                       output = initial_output[k],\n",
      "                                       score = 1.0)\n",
      "            partial_caption_data.append(TopN(config.beam_size))\n",
      "            partial_caption_data[-1].push(initial_beam)\n",
      "            complete_caption_data.append(TopN(config.beam_size))\n",
      "\n",
      "        # Run beam search\n",
      "        for idx in range(config.max_caption_length):\n",
      "            partial_caption_data_lists = []\n",
      "            for k in range(config.batch_size):\n",
      "                data = partial_caption_data[k].extract()\n",
      "                partial_caption_data_lists.append(data)\n",
      "                partial_caption_data[k].reset()\n",
      "\n",
      "            num_steps = 1 if idx == 0 else config.beam_size\n",
      "            for b in range(num_steps):\n",
      "                if idx == 0:\n",
      "                    last_word = np.zeros((config.batch_size), np.int32)\n",
      "                else:\n",
      "                    last_word = np.array([pcl[b].sentence[-1]\n",
      "                                        for pcl in partial_caption_data_lists],\n",
      "                                        np.int32)\n",
      "\n",
      "                last_memory = np.array([pcl[b].memory\n",
      "                                        for pcl in partial_caption_data_lists],\n",
      "                                        np.float32)\n",
      "                last_output = np.array([pcl[b].output\n",
      "                                        for pcl in partial_caption_data_lists],\n",
      "                                        np.float32)\n",
      "\n",
      "                memory, output, scores = sess.run(\n",
      "                    [self.memory, self.output, self.probs],\n",
      "                    feed_dict = {self.contexts: contexts,\n",
      "                                 self.last_word: last_word,\n",
      "                                 self.last_memory: last_memory,\n",
      "                                 self.last_output: last_output})\n",
      "\n",
      "                # Find the beam_size most probable next words\n",
      "                for k in range(config.batch_size):\n",
      "                    caption_data = partial_caption_data_lists[k][b]\n",
      "                    words_and_scores = list(enumerate(scores[k]))\n",
      "                    words_and_scores.sort(key=lambda x: -x[1])\n",
      "                    words_and_scores = words_and_scores[0:config.beam_size+1]\n",
      "\n",
      "                    # Append each of these words to the current partial caption\n",
      "                    for w, s in words_and_scores:\n",
      "                        sentence = caption_data.sentence + [w]\n",
      "                        score = caption_data.score * s\n",
      "                        beam = CaptionData(sentence,\n",
      "                                           memory[k],\n",
      "                                           output[k],\n",
      "                                           score)\n",
      "                        if vocabulary.words[w] == '.':\n",
      "                            complete_caption_data[k].push(beam)\n",
      "                        else:\n",
      "                            partial_caption_data[k].push(beam)\n",
      "\n",
      "        results = []\n",
      "        for k in range(config.batch_size):\n",
      "            if complete_caption_data[k].size() == 0:\n",
      "                complete_caption_data[k] = partial_caption_data[k]\n",
      "            results.append(complete_caption_data[k].extract(sort=True))\n",
      "\n",
      "        return results\n",
      "\n",
      "    def save(self):\n",
      "        \"\"\" Save the model. \"\"\"\n",
      "        config = self.config\n",
      "        data = {v.name: v.eval() for v in tf.global_variables()}\n",
      "        save_path = os.path.join(config.save_dir, str(self.global_step.eval()))\n",
      "\n",
      "        print((\" Saving the model to %s...\" % (save_path+\".npy\")))\n",
      "        np.save(save_path, data)\n",
      "        info_file = open(os.path.join(config.save_dir, \"config.pickle\"), \"wb\")\n",
      "        config_ = copy.copy(config)\n",
      "        config_.global_step = self.global_step.eval()\n",
      "        pickle.dump(config_, info_file)\n",
      "        info_file.close()\n",
      "        print(\"Model saved.\")\n",
      "\n",
      "    def load(self, sess, model_file=None):\n",
      "        \"\"\" Load the model. \"\"\"\n",
      "        config = self.config\n",
      "        if model_file is not None:\n",
      "            save_path = model_file\n",
      "        else:\n",
      "            info_path = os.path.join(config.save_dir, \"config.pickle\")\n",
      "            info_file = open(info_path, \"rb\")\n",
      "            config = pickle.load(info_file)\n",
      "            global_step = config.global_step\n",
      "            info_file.close()\n",
      "            save_path = os.path.join(config.save_dir,\n",
      "                                     str(global_step)+\".npy\")\n",
      "\n",
      "        print(\"Loading the model from %s...\" %save_path)\n",
      "        data_dict = np.load(save_path).item()\n",
      "        count = 0\n",
      "        for v in tqdm(tf.global_variables()):\n",
      "            if v.name in data_dict.keys():\n",
      "                sess.run(v.assign(data_dict[v.name]))\n",
      "                count += 1\n",
      "        print(\"%d tensors loaded.\" %count)\n",
      "\n",
      "    def load_cnn(self, session, data_path, ignore_missing=True):\n",
      "        \"\"\" Load a pretrained CNN model. \"\"\"\n",
      "        print(\"Loading the CNN from %s...\" %data_path)\n",
      "        data_dict = np.load(data_path).item()\n",
      "        count = 0\n",
      "        for op_name in tqdm(data_dict):\n",
      "            with tf.variable_scope(op_name, reuse = True):\n",
      "                for param_name, data in data_dict[op_name].iteritems():\n",
      "                    try:\n",
      "                        var = tf.get_variable(param_name)\n",
      "                        session.run(var.assign(data))\n",
      "                        count += 1\n",
      "                    except ValueError:\n",
      "                        pass\n",
      "        print(\"%d tensors loaded.\" %count)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search3 = \"train a neural network for image reconition\"\n",
    "query3 = top_n_code(search3, doc_strings, embed_vecs, 10)\n",
    "print(query3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew_mamroth/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rekall Memory Forensics\n",
      "# Copyright (C) 2007-2011 Volatile Systems\n",
      "# Copyright 2013 Google Inc. All Rights Reserved.\n",
      "#\n",
      "# Additional Authors:\n",
      "# Michael Cohen <scudette@users.sourceforge.net>\n",
      "# Mike Auty <mike.auty@gmail.com>\n",
      "#\n",
      "# This program is free software; you can redistribute it and/or modify\n",
      "# it under the terms of the GNU General Public License as published by\n",
      "# the Free Software Foundation; either version 2 of the License, or (at\n",
      "# your option) any later version.\n",
      "#\n",
      "# This program is distributed in the hope that it will be useful, but\n",
      "# WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\n",
      "# General Public License for more details.\n",
      "#\n",
      "# You should have received a copy of the GNU General Public License\n",
      "# along with this program; if not, write to the Free Software\n",
      "# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA\n",
      "#\n",
      "\n",
      "# pylint: disable=protected-access\n",
      "\n",
      "from future import standard_library\n",
      "standard_library.install_aliases()\n",
      "from rekall import testlib\n",
      "from rekall_lib import utils\n",
      "\n",
      "from rekall.plugins.common import memmap\n",
      "from rekall.plugins.windows import common\n",
      "\n",
      "\n",
      "class WinPsList(common.WinProcessFilter):\n",
      "    \"\"\"List processes for windows.\"\"\"\n",
      "\n",
      "    __name = \"pslist\"\n",
      "\n",
      "    eprocess = None\n",
      "\n",
      "    table_header = [\n",
      "        dict(type=\"_EPROCESS\", name=\"_EPROCESS\"),\n",
      "        dict(name=\"ppid\", width=6, align=\"r\"),\n",
      "        dict(name=\"thread_count\", width=6, align=\"r\"),\n",
      "        dict(name=\"handle_count\", width=8, align=\"r\"),\n",
      "        dict(name=\"session_id\", width=6, align=\"r\"),\n",
      "        dict(name=\"wow64\", width=6),\n",
      "        dict(name=\"process_create_time\", width=24),\n",
      "        dict(name=\"process_exit_time\", width=24)\n",
      "    ]\n",
      "\n",
      "    def column_types(self):\n",
      "        result = self._row(self.session.profile._EPROCESS())\n",
      "        result[\"handle_count\"] = result[\"ppid\"]\n",
      "        result[\"session_id\"] = result[\"ppid\"]\n",
      "\n",
      "        return result\n",
      "\n",
      "    def _row(self, task):\n",
      "        return dict(_EPROCESS=task,\n",
      "                    ppid=task.InheritedFromUniqueProcessId,\n",
      "                    thread_count=task.ActiveThreads,\n",
      "                    handle_count=task.ObjectTable.m(\"HandleCount\"),\n",
      "                    session_id=task.SessionId,\n",
      "                    wow64=task.IsWow64,\n",
      "                    process_create_time=task.CreateTime,\n",
      "                    process_exit_time=task.ExitTime)\n",
      "\n",
      "    def collect(self):\n",
      "        for task in self.filter_processes():\n",
      "            yield self._row(task)\n",
      "\n",
      "\n",
      "class WinDllList(common.WinProcessFilter):\n",
      "    \"\"\"Prints a list of dll modules mapped into each process.\"\"\"\n",
      "\n",
      "    __name = \"dlllist\"\n",
      "\n",
      "    table_header = [\n",
      "        dict(name=\"divider\", type=\"Divider\"),\n",
      "        dict(name=\"_EPROCESS\", hidden=True),\n",
      "        dict(name=\"base\", style=\"address\"),\n",
      "        dict(name=\"size\", style=\"address\"),\n",
      "        dict(name=\"reason\", width=30),\n",
      "        dict(name=\"dll_path\"),\n",
      "    ]\n",
      "\n",
      "    def collect(self):\n",
      "        for task in self.filter_processes():\n",
      "            pid = task.UniqueProcessId\n",
      "\n",
      "            divider = \"{0} pid: {1:6}\\n\".format(task.ImageFileName, pid)\n",
      "\n",
      "            if task.Peb:\n",
      "                divider += u\"Command line : {0}\\n\".format(\n",
      "                    task.Peb.ProcessParameters.CommandLine)\n",
      "\n",
      "                divider += u\"{0}\\n\\n\".format(task.Peb.CSDVersion)\n",
      "                yield dict(divider=divider)\n",
      "\n",
      "                for m in task.get_load_modules():\n",
      "                    yield dict(base=m.DllBase,\n",
      "                               size=m.SizeOfImage,\n",
      "                               reason=m.LoadReason,\n",
      "                               dll_path=m.FullDllName,\n",
      "                               _EPROCESS=task)\n",
      "            else:\n",
      "                yield dict(divider=\"Unable to read PEB for task.\\n\")\n",
      "\n",
      "\n",
      "class WinMemMap(memmap.MemmapMixIn, common.WinProcessFilter):\n",
      "    \"\"\"Calculates the memory regions mapped by a process.\"\"\"\n",
      "    __name = \"memmap\"\n",
      "\n",
      "    def _get_highest_user_address(self):\n",
      "        return self.profile.get_constant_object(\n",
      "            \"MmHighestUserAddress\", \"Pointer\").v()\n",
      "\n",
      "\n",
      "class Threads(common.WinProcessFilter):\n",
      "    \"\"\"Enumerate threads.\"\"\"\n",
      "    name = \"threads\"\n",
      "\n",
      "    table_header = [\n",
      "        dict(name=\"_ETHREAD\", style=\"address\"),\n",
      "        dict(name=\"pid\", align=\"r\", width=6),\n",
      "        dict(name=\"tid\", align=\"r\", width=6),\n",
      "        dict(name=\"start\", style=\"address\"),\n",
      "        dict(name=\"start_symbol\", width=30),\n",
      "        dict(name=\"Process\", width=16),\n",
      "        dict(name=\"win32_start\", style=\"address\"),\n",
      "        dict(name=\"win32_start_symb\")\n",
      "    ]\n",
      "\n",
      "    def collect(self):\n",
      "        cc = self.session.plugins.cc()\n",
      "        with cc:\n",
      "            for task in self.filter_processes():\n",
      "                # Resolve names in the process context.\n",
      "                cc.SwitchProcessContext(process=task)\n",
      "\n",
      "                for thread in task.ThreadListHead.list_of_type(\n",
      "                        \"_ETHREAD\", \"ThreadListEntry\"):\n",
      "\n",
      "                    yield dict(_ETHREAD=thread,\n",
      "                               pid=thread.Cid.UniqueProcess,\n",
      "                               tid=thread.Cid.UniqueThread,\n",
      "                               start=thread.StartAddress,\n",
      "                               start_symbol=utils.FormattedAddress(\n",
      "                                   self.session.address_resolver,\n",
      "                                   thread.StartAddress),\n",
      "                               Process=task.ImageFileName,\n",
      "                               win32_start=thread.Win32StartAddress,\n",
      "                               win32_start_symb=utils.FormattedAddress(\n",
      "                                   self.session.address_resolver,\n",
      "                                   thread.Win32StartAddress,\n",
      "                                   ))\n",
      "\n",
      "\n",
      "class WinMemDump(memmap.MemDumpMixin, common.WinProcessFilter):\n",
      "    \"\"\"Dump windows processes.\"\"\"\n",
      "\n",
      "\n",
      "class TestWinMemDump(testlib.HashChecker):\n",
      "    \"\"\"Test the pslist module.\"\"\"\n",
      "\n",
      "    PARAMETERS = dict(\n",
      "        commandline=\"memdump %(pids)s --dump_dir %(tempdir)s\",\n",
      "        pid=2624)\n",
      "\n",
      "\n",
      "class TestMemmap(testlib.SimpleTestCase):\n",
      "    \"\"\"Test the pslist module.\"\"\"\n",
      "\n",
      "    PARAMETERS = dict(\n",
      "        commandline=\"memmap %(pids)s\",\n",
      "        pid=2624)\n",
      "\n",
      "\n",
      "class TestMemmapCoalesce(testlib.SimpleTestCase):\n",
      "    \"\"\"Make sure that memmaps are coalesced properly.\"\"\"\n",
      "\n",
      "    PARAMETERS = dict(commandline=\"memmap %(pids)s --coalesce\",\n",
      "                      pid=2624)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search4 = \"list the first 100 Fibonacci Numbers\"\n",
    "query4 = top_n_code(search4, doc_strings, embed_vecs, 10)\n",
    "print(query4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew_mamroth/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:644: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#     Copyright 2018, Kay Hayen, mailto:kay.hayen@gmail.com\n",
      "#\n",
      "#     Part of \"Nuitka\", an optimizing Python compiler that is compatible and\n",
      "#     integrates with CPython, but also works on its own.\n",
      "#\n",
      "#     Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "#     you may not use this file except in compliance with the License.\n",
      "#     You may obtain a copy of the License at\n",
      "#\n",
      "#        http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "#     Unless required by applicable law or agreed to in writing, software\n",
      "#     distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "#     See the License for the specific language governing permissions and\n",
      "#     limitations under the License.\n",
      "#\n",
      "\"\"\" Syntax highlighting for Python.\n",
      "\n",
      "Inspired/copied from by http://diotavelli.net/PyQtWiki/Python%20syntax%20highlighting\n",
      "\"\"\"\n",
      "\n",
      "from PyQt5.QtCore import (\n",
      "    QRegExp  # @UnresolvedImport pylint: disable=I0021,import-error\n",
      ")\n",
      "from PyQt5.QtGui import (\n",
      "    QColor  # @UnresolvedImport pylint: disable=I0021,import-error\n",
      ")\n",
      "from PyQt5.QtGui import (\n",
      "    QFont  # @UnresolvedImport pylint: disable=I0021,import-error\n",
      ")\n",
      "from PyQt5.QtGui import (\n",
      "    QSyntaxHighlighter  # @UnresolvedImport pylint: disable=I0021,import-error\n",
      ")\n",
      "from PyQt5.QtGui import (\n",
      "    QTextCharFormat  # @UnresolvedImport pylint: disable=I0021,import-error\n",
      ")\n",
      "\n",
      "\n",
      "def createTextFormat(color, style = \"\"):\n",
      "    \"\"\"Return a QTextCharFormat with the given attributes.\n",
      "    \"\"\"\n",
      "    _color = QColor()\n",
      "    _color.setNamedColor(color)\n",
      "\n",
      "    _format = QTextCharFormat()\n",
      "    _format.setForeground(_color)\n",
      "    if \"bold\" in style:\n",
      "        _format.setFontWeight(QFont.Bold)\n",
      "    if \"italic\" in style:\n",
      "        _format.setFontItalic(True)\n",
      "\n",
      "    return _format\n",
      "\n",
      "\n",
      "# Syntax styles that can be shared by all languages\n",
      "STYLES = {\n",
      "    \"keyword\"  : createTextFormat(\"blue\"),\n",
      "    \"operator\" : createTextFormat(\"red\"),\n",
      "    \"brace\"    : createTextFormat(\"darkGray\"),\n",
      "    \"defclass\" : createTextFormat(\"black\", \"bold\"),\n",
      "    \"string\"   : createTextFormat(\"magenta\"),\n",
      "    \"string2\"  : createTextFormat(\"darkMagenta\"),\n",
      "    \"comment\"  : createTextFormat(\"darkGreen\", \"italic\"),\n",
      "    \"self\"     : createTextFormat(\"black\", \"italic\"),\n",
      "    \"numbers\"  : createTextFormat(\"brown\"),\n",
      "}\n",
      "\n",
      "\n",
      "class PythonHighlighter(QSyntaxHighlighter):\n",
      "    \"\"\" Syntax highlighter for the Python language.\n",
      "    \"\"\"\n",
      "    # Python keywords\n",
      "    keywords = [\n",
      "        \"and\", \"assert\", \"break\", \"class\", \"continue\", \"def\",\n",
      "        \"del\", \"elif\", \"else\", \"except\", \"exec\", \"finally\",\n",
      "        \"for\", \"from\", \"global\", \"if\", \"import\", \"in\",\n",
      "        \"is\", \"lambda\", \"not\", \"or\", \"pass\", \"print\",\n",
      "        \"raise\", \"return\", \"try\", \"while\", \"with\", \"yield\",\n",
      "        \"None\", \"True\", \"False\",\n",
      "    ]\n",
      "\n",
      "    # Python operators\n",
      "    operators = [\n",
      "        '=',\n",
      "        # Comparison\n",
      "        \"==\", \"!=\", '<', \"<=\", '>', \">=\",\n",
      "        # Arithmetic\n",
      "        \"\\+\", '-', \"\\*\", '/', \"//\", \"\\%\", \"\\*\\*\",\n",
      "        # In-place\n",
      "        \"\\+=\", \"-=\", \"\\*=\", \"/=\", \"\\%=\",\n",
      "        # Bitwise\n",
      "        \"\\^\", \"\\|\", \"\\&\", \"\\~\", \">>\", \"<<\",\n",
      "    ]\n",
      "\n",
      "    # Python braces\n",
      "    braces = [\n",
      "        \"\\{\", \"\\}\", \"\\(\", \"\\)\", \"\\[\", \"\\]\",\n",
      "    ]\n",
      "    def __init__(self, document):\n",
      "        QSyntaxHighlighter.__init__(self, document)\n",
      "\n",
      "        # Multi-line strings (expression, flag, style)\n",
      "        # The triple-quotes in these two lines will mess up the\n",
      "        # syntax highlighting from this point onward\n",
      "        self.tri_single = (QRegExp(\"'''\"), 1, STYLES[\"string2\"])\n",
      "        self.tri_double = (QRegExp('\"\"\"'), 2, STYLES[\"string2\"])\n",
      "\n",
      "        rules = []\n",
      "\n",
      "        # Keyword, operator, and brace rules\n",
      "        rules += [(r'\\b%s\\b' % w, 0, STYLES[\"keyword\"])\n",
      "            for w in PythonHighlighter.keywords]\n",
      "        rules += [(r'%s' % o, 0, STYLES[\"operator\"])\n",
      "            for o in PythonHighlighter.operators]\n",
      "        rules += [(r'%s' % b, 0, STYLES[\"brace\"])\n",
      "            for b in PythonHighlighter.braces]\n",
      "\n",
      "        # All other rules\n",
      "        rules += [\n",
      "            # 'self'\n",
      "            (r'\\bself\\b', 0, STYLES[\"self\"]),\n",
      "\n",
      "            # Double-quoted string, possibly containing escape sequences\n",
      "            (r'\"[^\"\\\\]*(\\\\.[^\"\\\\]*)*\"', 0, STYLES[\"string\"]),\n",
      "            # Single-quoted string, possibly containing escape sequences\n",
      "            (r\"'[^'\\\\]*(\\\\.[^'\\\\]*)*'\", 0, STYLES[\"string\"]),\n",
      "\n",
      "            # 'def' followed by an identifier\n",
      "            (r'\\bdef\\b\\s*(\\w+)', 1, STYLES[\"defclass\"]),\n",
      "            # 'class' followed by an identifier\n",
      "            (r'\\bclass\\b\\s*(\\w+)', 1, STYLES[\"defclass\"]),\n",
      "\n",
      "            # From '#' until a newline\n",
      "            (r'#[^\\n]*', 0, STYLES[\"comment\"]),\n",
      "\n",
      "            # Numeric literals\n",
      "            (r'\\b[+-]?[0-9]+[lL]?\\b', 0, STYLES[\"numbers\"]),\n",
      "            (r'\\b[+-]?0[xX][0-9A-Fa-f]+[lL]?\\b', 0, STYLES[\"numbers\"]),\n",
      "            (r'\\b[+-]?[0-9]+(?:\\.[0-9]+)?(?:[eE][+-]?[0-9]+)?\\b', 0, STYLES[\"numbers\"]),\n",
      "        ]\n",
      "\n",
      "        # Build a QRegExp for each pattern\n",
      "        self.rules = [(QRegExp(pat), index, fmt)\n",
      "            for (pat, index, fmt) in rules]\n",
      "\n",
      "\n",
      "    def highlightBlock(self, text):\n",
      "        \"\"\"Apply syntax highlighting to the given block of text.\n",
      "        \"\"\"\n",
      "        # Do other syntax formatting\n",
      "        for expression, nth, display_format in self.rules:\n",
      "            index = expression.indexIn(text, 0)\n",
      "\n",
      "            while index >= 0:\n",
      "                # We actually want the index of the nth match\n",
      "                index = expression.pos(nth)\n",
      "                length = expression.cap(nth).length()\n",
      "                self.setFormat(index, length, display_format)\n",
      "                index = expression.indexIn(text, index + length)\n",
      "\n",
      "        self.setCurrentBlockState(0)\n",
      "\n",
      "        # Do multi-line strings\n",
      "        in_multiline = self.match_multiline(text, *self.tri_single)\n",
      "        if not in_multiline:\n",
      "            in_multiline = self.match_multiline(text, *self.tri_double)\n",
      "\n",
      "\n",
      "    def match_multiline(self, text, delimiter, in_state, style):\n",
      "        \"\"\"Do highlighting of multi-line strings. ``delimiter`` should be a\n",
      "        ``QRegExp`` for triple-single-quotes or triple-double-quotes, and\n",
      "        ``in_state`` should be a unique integer to represent the corresponding\n",
      "        state changes when inside those strings. Returns True if we're still\n",
      "        inside a multi-line string when this function is finished.\n",
      "        \"\"\"\n",
      "        # If inside triple-single quotes, start at 0\n",
      "        if self.previousBlockState() == in_state:\n",
      "            start = 0\n",
      "            add = 0\n",
      "        # Otherwise, look for the delimiter on this line\n",
      "        else:\n",
      "            start = delimiter.indexIn(text)\n",
      "            # Move past this match\n",
      "            add = delimiter.matchedLength()\n",
      "\n",
      "        # As long as there's a delimiter match on this line...\n",
      "        while start >= 0:\n",
      "            # Look for the ending delimiter\n",
      "            end = delimiter.indexIn(text, start + add)\n",
      "            # Ending delimiter on this line?\n",
      "            if end >= add:\n",
      "                length = end - start + add + delimiter.matchedLength()\n",
      "                self.setCurrentBlockState(0)\n",
      "            # No; multi-line string\n",
      "            else:\n",
      "                self.setCurrentBlockState(in_state)\n",
      "                length = text.length() - start + add\n",
      "            # Apply formatting\n",
      "            self.setFormat(start, length, style)\n",
      "            # Look for the next match\n",
      "            start = delimiter.indexIn(text, start + length)\n",
      "\n",
      "        # Return True if still inside a multi-line string, False otherwise\n",
      "        if self.currentBlockState() == in_state:\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "def addPythonHighlighter(document):\n",
      "    PythonHighlighter(document)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search5 = \"semantic search tool for text\"\n",
    "query5 = top_n_code(search5, doc_strings, embed_vecs, 10)\n",
    "print(query5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
